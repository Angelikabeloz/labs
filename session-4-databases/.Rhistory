library(DBI)
library(tidyverse)
p
?update.packages
update.packages
update.packages()
update.packages(ask=F)
library(DBI)
library(tidyverse)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
)
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T
)
# generate reference table from the database
flights_db <- tbl(con, "flights")
flights_db # note that it's a remote source; the table is not stored in our local environment
# perform various queries
flights_db %>% select(year:day, dep_delay, arr_delay)
flights_db %>% filter(dep_delay > 240)
flights_db %>%
group_by(dest) %>%
summarise(delay = mean(dep_time))
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
tailnum_delay_db <- flights_db %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay),
n = n()
) %>%
arrange(desc(delay)) %>%
filter(n > 100)
tailnum_delay_db
# This also has some downsides.
# Exhibit A: Because there’s generally no way to determine how many rows a query will return unless you actually run it, nrow() is always NA.
nrow(tailnum_delay_db)
# Exhibit B: Because you can’t find the last few rows without executing the whole query, you can’t use tail().
tail(tailnum_delay_db)
# If you then want to pull the data into a local data frame, use collect():
tailnum_delay <- tailnum_delay_db %>% collect()
tailnum_delay
tailnum_delay_db %>% show_query()
copy_to(
dest = con,
df = nycflights13::planes,
name = "planes",
temporary = FALSE,
indexes = "tailnum"
)
copy_to(
dest = con,
df = nycflights13::airlines,
name = "airlines",
temporary = FALSE,
indexes = "carrier"
)
copy_to(
dest = con,
df = nycflights13::airports,
name = "airports",
temporary = FALSE,
indexes = "faa"
)
copy_to(
dest = con,
df = nycflights13::weather,
name = "weather",
temporary = FALSE,
indexes = list(
c("year", "month", "day", "hour", "origin")
)
)
## List tables in our "con" database connection
dbListTables(con)
planes_db = tbl(con, 'planes')
left_join(
flights_db,
planes_db %>% rename(year_built = year),
by = "tailnum" ## Important: Be specific about the joining column
) %>%
select(year, month, day, dep_time, arr_time, carrier, flight, tailnum,
year_built, type, model)
sql_query <- "SELECT * FROM flights WHERE dep_delay > 240.0 LIMIT 5"
dbGetQuery(con, sql_query)
DBI::dbDisconnect(con)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, DBI, bigrquery, nycflights13)
pacman::p_load(tidyverse, DBI, bigrquery, nycflights13)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
df <- data.frame(
a = rnorm(100, 5, 2),
b = rnorm(100, 100, 15),
c = rnorm(100, 2, 1),
d = rnorm(100, 36, 7)
)
df$a <- (df$a - mean(df$a, na.rm = TRUE)) / sd(df$a, na.rm = TRUE)
df$b <- (df$b - mean(df$b, na.rm = TRUE)) / sd(df$a, na.rm = TRUE) # spot the mistake?
df$c <- (df$c - mean(df$c, na.rm = TRUE)) / sd(df$c, na.rm = TRUE)
df$d <- (df$d - mean(df$d, na.rm = TRUE)) / sd(df$d, na.rm = TRUE)
zscale <- function(x){
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
zscale <- function(x){
if (is.numeric(x)) {
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
}
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# you can also use your function with a pipe!
df$d %>% zscale()
# repetitive code
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# equivalent iteration
for (i in seq_along(df)) {       # seq_along() similar to length()
df[[i]] <- zscale(df[[i]])     # [[]] because we are working on single elements
}
# repetitive code
mean(df$a)
mean(df$b)
mean(df$c)
mean(df$d)
# equivalent map function
map_dbl(df,mean)
# map function in tidyverse style
df %>% map_dbl(mean)
pacman::p_load(DBI, bigrquery, nycflights13)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T
)
# generate reference table from the database
flights_db <- tbl(con, "flights")
flights_db
# perform various queries
flights_db %>% select(year:day, dep_delay, arr_delay)
flights_db %>% filter(dep_delay > 240)
flights_db %>%
group_by(dest) %>%
summarise(delay = mean(dep_time))
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
tailnum_delay_db <- flights_db %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay),
n = n()
) %>%
arrange(desc(delay)) %>%
filter(n > 100)
nrow(tailnum_delay_db)
tail(tailnum_delay_db)
tailnum_delay <- tailnum_delay_db %>% collect()
tailnum_delay
tailnum_delay_db %>% show_query()
copy_to(
dest = con,
df = nycflights13::planes,
name = "planes",
temporary = FALSE,
indexes = "tailnum"
)
copy_to(
dest = con,
df = nycflights13::airlines,
name = "airlines",
temporary = FALSE,
indexes = "carrier"
)
copy_to(
dest = con,
df = nycflights13::airports,
name = "airports",
temporary = FALSE,
indexes = "faa"
)
copy_to(
dest = con,
df = nycflights13::weather,
name = "weather",
temporary = FALSE,
indexes = list(
c("year", "month", "day", "hour", "origin")
)
)
dbListTables(con)
planes_db = tbl(con, 'planes')
left_join(
flights_db,
planes_db %>% rename(year_built = year),
by = "tailnum" ## Important: Be specific about the joining column
) %>%
select(year, month, day, dep_time, arr_time, carrier, flight, tailnum,
year_built, type, model)
sql_query <- "SELECT * FROM flights WHERE dep_delay > 240.0 LIMIT 5"
dbGetQuery(con, sql_query)
DBI::dbDisconnect(con)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
df <- data.frame(
a = rnorm(100, 5, 2),
b = rnorm(100, 100, 15),
c = rnorm(100, 2, 1),
d = rnorm(100, 36, 7)
)
df$a <- (df$a - mean(df$a, na.rm = TRUE)) / sd(df$a, na.rm = TRUE)
df$b <- (df$b - mean(df$b, na.rm = TRUE)) / sd(df$a, na.rm = TRUE) # spot the mistake?
df$c <- (df$c - mean(df$c, na.rm = TRUE)) / sd(df$c, na.rm = TRUE)
df$d <- (df$d - mean(df$d, na.rm = TRUE)) / sd(df$d, na.rm = TRUE)
zscale <- function(x){
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
zscale <- function(x){
if (is.numeric(x)) {
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
}
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# you can also use your function with a pipe!
df$d %>% zscale()
# repetitive code
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# equivalent iteration
for (i in seq_along(df)) {       # seq_along() similar to length()
df[[i]] <- zscale(df[[i]])     # [[]] because we are working on single elements
}
# repetitive code
mean(df$a)
mean(df$b)
mean(df$c)
mean(df$d)
# equivalent map function
map_dbl(df,mean)
# map function in tidyverse style
df %>% map_dbl(mean)
pacman::p_load(RSQLite, DBI, bigrquery, nycflights13)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
summary(con)
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T # throws error as table already exists
)
DBI::dbListTables(con)
?dbConnect
palmerpenguins::penguins_raw
glimpse(palmerpenguins::penguins_raw)
glimpse(palmerpenguins::penguins)
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rnorm(nrow(penguins), mean = 1.5, sd = 1))
penguins
penguins_emotions
penguins_emotions$emotions
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins), mean = 1.5, sd = 1))
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins))
?rpois
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins), lambda = 3)
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 3))
penguins_emotions$emotions
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 1))
penguins_emotions$emotions
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 0.5))
penguins_emotions$emotions
