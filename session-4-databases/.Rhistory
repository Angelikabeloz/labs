library(DBI)
library(tidyverse)
p
?update.packages
update.packages
update.packages()
update.packages(ask=F)
library(DBI)
library(tidyverse)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
)
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T
)
# generate reference table from the database
flights_db <- tbl(con, "flights")
flights_db # note that it's a remote source; the table is not stored in our local environment
# perform various queries
flights_db %>% select(year:day, dep_delay, arr_delay)
flights_db %>% filter(dep_delay > 240)
flights_db %>%
group_by(dest) %>%
summarise(delay = mean(dep_time))
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
tailnum_delay_db <- flights_db %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay),
n = n()
) %>%
arrange(desc(delay)) %>%
filter(n > 100)
tailnum_delay_db
# This also has some downsides.
# Exhibit A: Because there’s generally no way to determine how many rows a query will return unless you actually run it, nrow() is always NA.
nrow(tailnum_delay_db)
# Exhibit B: Because you can’t find the last few rows without executing the whole query, you can’t use tail().
tail(tailnum_delay_db)
# If you then want to pull the data into a local data frame, use collect():
tailnum_delay <- tailnum_delay_db %>% collect()
tailnum_delay
tailnum_delay_db %>% show_query()
copy_to(
dest = con,
df = nycflights13::planes,
name = "planes",
temporary = FALSE,
indexes = "tailnum"
)
copy_to(
dest = con,
df = nycflights13::airlines,
name = "airlines",
temporary = FALSE,
indexes = "carrier"
)
copy_to(
dest = con,
df = nycflights13::airports,
name = "airports",
temporary = FALSE,
indexes = "faa"
)
copy_to(
dest = con,
df = nycflights13::weather,
name = "weather",
temporary = FALSE,
indexes = list(
c("year", "month", "day", "hour", "origin")
)
)
## List tables in our "con" database connection
dbListTables(con)
planes_db = tbl(con, 'planes')
left_join(
flights_db,
planes_db %>% rename(year_built = year),
by = "tailnum" ## Important: Be specific about the joining column
) %>%
select(year, month, day, dep_time, arr_time, carrier, flight, tailnum,
year_built, type, model)
sql_query <- "SELECT * FROM flights WHERE dep_delay > 240.0 LIMIT 5"
dbGetQuery(con, sql_query)
DBI::dbDisconnect(con)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, DBI, bigrquery, nycflights13)
pacman::p_load(tidyverse, DBI, bigrquery, nycflights13)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
df <- data.frame(
a = rnorm(100, 5, 2),
b = rnorm(100, 100, 15),
c = rnorm(100, 2, 1),
d = rnorm(100, 36, 7)
)
df$a <- (df$a - mean(df$a, na.rm = TRUE)) / sd(df$a, na.rm = TRUE)
df$b <- (df$b - mean(df$b, na.rm = TRUE)) / sd(df$a, na.rm = TRUE) # spot the mistake?
df$c <- (df$c - mean(df$c, na.rm = TRUE)) / sd(df$c, na.rm = TRUE)
df$d <- (df$d - mean(df$d, na.rm = TRUE)) / sd(df$d, na.rm = TRUE)
zscale <- function(x){
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
zscale <- function(x){
if (is.numeric(x)) {
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
}
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# you can also use your function with a pipe!
df$d %>% zscale()
# repetitive code
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# equivalent iteration
for (i in seq_along(df)) {       # seq_along() similar to length()
df[[i]] <- zscale(df[[i]])     # [[]] because we are working on single elements
}
# repetitive code
mean(df$a)
mean(df$b)
mean(df$c)
mean(df$d)
# equivalent map function
map_dbl(df,mean)
# map function in tidyverse style
df %>% map_dbl(mean)
pacman::p_load(DBI, bigrquery, nycflights13)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
con <- DBI::dbConnect(RMariaDB::MariaDB(),
host = "database.rstudio.com",
user = "hadley",
password = rstudioapi::askForPassword("Database password")
)
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T
)
# generate reference table from the database
flights_db <- tbl(con, "flights")
flights_db
# perform various queries
flights_db %>% select(year:day, dep_delay, arr_delay)
flights_db %>% filter(dep_delay > 240)
flights_db %>%
group_by(dest) %>%
summarise(delay = mean(dep_time))
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
flights_db %>%
filter(distance > 75) %>%
group_by(origin, hour) %>%
summarise(delay = mean(dep_delay, na.rm = TRUE)) %>%
ggplot(aes(hour, delay, color = origin)) + geom_line()
tailnum_delay_db <- flights_db %>%
group_by(tailnum) %>%
summarise(
delay = mean(arr_delay),
n = n()
) %>%
arrange(desc(delay)) %>%
filter(n > 100)
nrow(tailnum_delay_db)
tail(tailnum_delay_db)
tailnum_delay <- tailnum_delay_db %>% collect()
tailnum_delay
tailnum_delay_db %>% show_query()
copy_to(
dest = con,
df = nycflights13::planes,
name = "planes",
temporary = FALSE,
indexes = "tailnum"
)
copy_to(
dest = con,
df = nycflights13::airlines,
name = "airlines",
temporary = FALSE,
indexes = "carrier"
)
copy_to(
dest = con,
df = nycflights13::airports,
name = "airports",
temporary = FALSE,
indexes = "faa"
)
copy_to(
dest = con,
df = nycflights13::weather,
name = "weather",
temporary = FALSE,
indexes = list(
c("year", "month", "day", "hour", "origin")
)
)
dbListTables(con)
planes_db = tbl(con, 'planes')
left_join(
flights_db,
planes_db %>% rename(year_built = year),
by = "tailnum" ## Important: Be specific about the joining column
) %>%
select(year, month, day, dep_time, arr_time, carrier, flight, tailnum,
year_built, type, model)
sql_query <- "SELECT * FROM flights WHERE dep_delay > 240.0 LIMIT 5"
dbGetQuery(con, sql_query)
DBI::dbDisconnect(con)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
df <- data.frame(
a = rnorm(100, 5, 2),
b = rnorm(100, 100, 15),
c = rnorm(100, 2, 1),
d = rnorm(100, 36, 7)
)
df$a <- (df$a - mean(df$a, na.rm = TRUE)) / sd(df$a, na.rm = TRUE)
df$b <- (df$b - mean(df$b, na.rm = TRUE)) / sd(df$a, na.rm = TRUE) # spot the mistake?
df$c <- (df$c - mean(df$c, na.rm = TRUE)) / sd(df$c, na.rm = TRUE)
df$d <- (df$d - mean(df$d, na.rm = TRUE)) / sd(df$d, na.rm = TRUE)
zscale <- function(x){
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
zscale <- function(x){
if (is.numeric(x)) {
(x - mean(x, na.rm = T) / sd(x, na.rm = T))
}
}
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# you can also use your function with a pipe!
df$d %>% zscale()
# repetitive code
df$a <- zscale(df$a)
df$b <- zscale(df$b)
df$c <- zscale(df$c)
df$d <- zscale(df$d)
# equivalent iteration
for (i in seq_along(df)) {       # seq_along() similar to length()
df[[i]] <- zscale(df[[i]])     # [[]] because we are working on single elements
}
# repetitive code
mean(df$a)
mean(df$b)
mean(df$c)
mean(df$d)
# equivalent map function
map_dbl(df,mean)
# map function in tidyverse style
df %>% map_dbl(mean)
pacman::p_load(RSQLite, DBI, bigrquery, nycflights13)
# set up connection with DBI and RSQLite
con <- dbConnect(RSQLite::SQLite(), ":memory:")
summary(con)
# upload local data frame into remote data source; here: database
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights")
copy_to(
dest = con,
df = nycflights13::flights,
name = "flights",
temporary = FALSE,
indexes = list(
c("year", "month", "day"),
"carrier",
"tailnum",
"dest"
),
overwrite = T # throws error as table already exists
)
DBI::dbListTables(con)
?dbConnect
palmerpenguins::penguins_raw
glimpse(palmerpenguins::penguins_raw)
glimpse(palmerpenguins::penguins)
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rnorm(nrow(penguins), mean = 1.5, sd = 1))
penguins
penguins_emotions
penguins_emotions$emotions
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins), mean = 1.5, sd = 1))
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins))
?rpois
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(nrow(penguins), lambda = 3)
penguins <- palmerpenguins::penguins
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 3))
penguins_emotions$emotions
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 1))
penguins_emotions$emotions
penguins_emotions <- penguins %>%
mutate(emotions = rpois(n = nrow(penguins), lambda = 0.5))
penguins_emotions$emotions
getwd()
study <- read_csv("./study.csv")
pacman::p_load(tidyverse)
study <- read_csv("./study.csv")
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr)
library(tidyverse)
study <- read_csv("./study.csv")
glimps(study)
library(tidyverse)
study <- read_csv("./study.csv")
glimpse(study)
replace_w_emoticons <- # If person is "happy", person is ":)",
# Else if person is emotion "neutral", person is ":/"
# Else person is ":("
mean_ci <- function(x, conf = 0.95) {
se <- sd(x) / sqrt(length(x))
alpha <- 1 - conf
mean(x) + se * qnorm(c(alpha / 2, 1 - alpha / 2))
}
mean_ci(study$age)
study <- tibble(
age       = c(32, 30, 32, 29, 24, 38, 25, 24, 48, 29, 22, 29, 24, 28, 24, 25,
25, 22, 25, 24, 25, 24, 23, 24, 31, 24, 29, 24, 22, 23, 26, 23,
24, 25, 24, 33, 27, 25, 26, 26, 26, 26, 26, 27, 24, 43, 25, 24,
27, 28, 29, 24, 26, 28, 25, 24, 26, 24, 26, 31, 24, 26, 31, 34,
26, 25, 27, NA),
age_group = c(2, 2, 2, 1, 1, 2, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 1, 1, 1, 1,
1, 1, 1, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 1, 1, 2,
2, 1, 1, 1, NA),
gender    = c(2, 1, 1, 2, 1, 1, 1, 2, 2, 2, 1, 1, 2, 1, 1, 1, 1, 2, 2, 1, 1,
1, 1, 2, 1, 1, 2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 2, 2, 1,
1, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 2, 1, 1, 2, 1, 2, 1,
1, 1, 2, 1, NA),
ht_in     = c(70, 63, 62, 67, 67, 58, 64, 69, 65, 68, 63, 68, 69, 66, 67, 65,
64, 75, 67, 63, 60, 67, 64, 73, 62, 69, 67, 62, 68, 66, 66, 62,
64, 68, NA, 68, 70, 68, 68, 66, 71, 61, 62, 64, 64, 63, 67, 66,
69, 76, NA, 63, 64, 65, 65, 71, 66, 65, 65, 71, 64, 71, 60, 62,
61, 69, 66, NA),
wt_lbs    = c(216, 106, 145, 195, 143, 125, 138, 140, 158, 167, 145, 297, 146,
125, 111, 125, 130, 182, 170, 121, 98, 150, 132, 250, 137, 124,
186, 148, 134, 155, 122, 142, 110, 132, 188, 176, 188, 166, 136,
147, 178, 125, 102, 140, 139, 60, 147, 147, 141, 232, 186, 212,
110, 110, 115, 154, 140, 150, 130, NA, 171, 156, 92, 122, 102,
163, 141, NA),
bmi       = c(30.99, 18.78, 26.52, 30.54, 22.39, 26.12, 23.69, 20.67, 26.29,
25.39, 25.68, 45.15, 21.56, 20.17, 17.38, 20.8, 22.31, 22.75,
26.62, 21.43, 19.14, 23.49, 22.66, 32.98, 25.05, 18.31, 29.13,
27.07, 20.37, 25.01, 19.69, 25.97, 18.88, 20.07, NA, 26.76,
26.97, 25.24, 20.68, 23.72, 24.82, 23.62, 18.65, 24.03, 23.86,
10.63, 23.02, 23.72, 20.82, 28.24, NA, 37.55, 18.88, 18.3,
19.13, 21.48, 22.59, 24.96, 21.63, NA, 29.35, 21.76, 17.97,
22.31, 19.27, 24.07, 22.76, NA),
bmi_3cat  = c(3, 1, 2, 3, 1, 2, 1, 1, 2, 2, 2, 3, 1, 1, 1, 1, 1, 1, 2, 1, 1,
1, 1, 3, 2, 1, 2, 2, 1, 2, 1, 2, 1, 1, NA, 2, 2, 2, 1, 1, 1, 1,
1, 1, 1, 1, 1, 1, 1, 2, NA, 3, 1, 1, 1, 1, 1, 1, 1, NA, 2, 1,
1, 1, 1, 1, 1, NA)
) %>%
mutate(emotions = rpois(n = nrow(study), lambda = 0.5)) %>%
mutate(emotions = case_when(emotions == 0 ~ "netural",
emotions == 1 ~ "happy",
TRUE ~ "sad"))   %>%
mutate(
age_group = factor(age_group, labels = c("Younger than 30", "30 and Older")),
gender    = factor(gender, labels = c("Female", "Male")),
bmi_3cat  = factor(bmi_3cat, labels = c("Normal", "Overweight", "Obese"))
) %>%
print()
write_csv(study, file = "/Users/tom/phd_hertie/courses/intro_data_science_fall_2021/labs/session-4-databases/study.csv" )
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr, learnR)
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE)
pacman::p_load(tidyverse, purrr, learnr)
View(mean_ci)
?dbConnect()
emo::ji_keyword
ji <- emo::ji_keyword
View(ji)
emo::ji("grin")
emo::ji("book")
emo::ji("floppy disk")
emo::ji("disk")
View(ji)
knitr::purl()
knitr::purl("4-databases.Rmd")
